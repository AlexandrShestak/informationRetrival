{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "def normalize_line(line):\n",
    "    line = unicode(line.lower(), \"utf-8\").replace('_', ' ')\n",
    "\n",
    "    words = [stemmer.stem(word) for word in tokenizer.tokenize(line) if word not in stopwords.words('russian')]\n",
    "    if not words:\n",
    "        return [stemmer.stem(word) for word in tokenizer.tokenize(line)]\n",
    "    elif len(words) > 1 and u\"википед\" in words:\n",
    "        words.remove(u\"википед\")\n",
    "        return words\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "N = 0\n",
    "\n",
    "with open('task3/urlid.csv', 'rb') as file:\n",
    "    for row in file:\n",
    "        document = {}\n",
    "        document['id'] = row[:row.find(',')]\n",
    "        document['title'] = normalize_line(urllib.unquote(row[row.find(',') + 1:-1]).replace('/wiki/', ''))\n",
    "   \n",
    "        documents[document['id']] = document\n",
    "        N += 1\n",
    "            \n",
    "            \n",
    "L_title = 0\n",
    "for document_index, document in documents.iteritems():\n",
    "    L_title += len(document['title'])\n",
    "    L_title /= float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index():\n",
    "    invert_index = {}\n",
    "    index_field = 'title'\n",
    "    for document_index, document in documents.iteritems():\n",
    "        for word in document[index_field]:\n",
    "            if word in invert_index.keys() and document_index in invert_index[word].keys():\n",
    "                pass\n",
    "            else:\n",
    "                if word not in invert_index:\n",
    "                    invert_index[word] = {document_index: document[index_field].count(word)}\n",
    "                else:\n",
    "                    invert_index[word][document_index] = document[index_field].count(word)\n",
    "    return invert_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_inverted_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_index(index, query_words, field_name, b, k1):\n",
    "    founded_documents_indexes = set()\n",
    "    for query_word in query_words:\n",
    "        if query_word in index:\n",
    "            founded_documents_indexes.update(index[query_word].keys())\n",
    " \n",
    "    documents_with_rsv = {}\n",
    "    for founded_document in founded_documents_indexes:\n",
    "        document_rsv = rsv(query_words, documents[founded_document][field_name], index, b, k1)\n",
    "        documents_with_rsv[founded_document] = document_rsv\n",
    "\n",
    "    return documents_with_rsv\n",
    "\n",
    "\n",
    "def rsv(query_words, document_words, inverse_index, b, k1):\n",
    "    L = L_title\n",
    "\n",
    "    rsv = 0\n",
    "    for query_word in query_words:\n",
    "        if query_word in inverse_index:\n",
    "            Nt = len(inverse_index[query_word])\n",
    "            ftd = document_words.count(query_word)\n",
    "            Ld = len(document_words)           \n",
    "            rsv += math.log1p(1 + (N + 0.5) / (Nt + 0.5)) * ftd * (k1 + 1)/(k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    return rsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_answer(b=0.75, k1=1.2):\n",
    "    field_name = 'title'\n",
    "    with open('answer11', 'w') as result_file:\n",
    "        with open('task3/qid.csv') as file:\n",
    "            for row in file:\n",
    "                query_words = normalize_line(row[row.find(',') + 1:-1])    \n",
    "                documents_with_rsv = search_in_index(index, query_words, field_name, b, k1)\n",
    "                top3 = [elem[0] for elem in\n",
    "                         sorted(documents_with_rsv.items(), key=operator.itemgetter(1), reverse=True)[:3]]\n",
    "                \n",
    "                result_file.write('%s,%s\\n' % (row[:row.find(',')], ','.join(top3)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_answer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
